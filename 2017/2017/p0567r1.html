<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <title>P0567r1.html</title>
  <meta name="generator" content="Haroopad 0.13.1" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <style>div.oembedall-githubrepos{border:1px solid #DDD;border-radius:4px;list-style-type:none;margin:0 0 10px;padding:8px 10px 0;font:13.34px/1.4 helvetica,arial,freesans,clean,sans-serif;width:452px;background-color:#fff}div.oembedall-githubrepos .oembedall-body{background:-moz-linear-gradient(center top,#FAFAFA,#EFEFEF);background:-webkit-gradient(linear,left top,left bottom,from(#FAFAFA),to(#EFEFEF));border-bottom-left-radius:4px;border-bottom-right-radius:4px;border-top:1px solid #EEE;margin-left:-10px;margin-top:8px;padding:5px 10px;width:100%}div.oembedall-githubrepos h3{font-size:14px;margin:0;padding-left:18px;white-space:nowrap}div.oembedall-githubrepos p.oembedall-description{color:#444;font-size:12px;margin:0 0 3px}div.oembedall-githubrepos p.oembedall-updated-at{color:#888;font-size:11px;margin:0}div.oembedall-githubrepos ul.oembedall-repo-stats{border:none;float:right;font-size:11px;font-weight:700;padding-left:15px;position:relative;z-index:5;margin:0}div.oembedall-githubrepos ul.oembedall-repo-stats li{border:none;color:#666;display:inline-block;list-style-type:none;margin:0!important}div.oembedall-githubrepos ul.oembedall-repo-stats li a{background-color:transparent;border:none;color:#666!important;background-position:5px -2px;background-repeat:no-repeat;border-left:1px solid #DDD;display:inline-block;height:21px;line-height:21px;padding:0 5px 0 23px}div.oembedall-githubrepos ul.oembedall-repo-stats li:first-child a{border-left:medium none;margin-right:-3px}div.oembedall-githubrepos ul.oembedall-repo-stats li a:hover{background:5px -27px no-repeat #4183C4;color:#FFF!important;text-decoration:none}div.oembedall-githubrepos ul.oembedall-repo-stats li:first-child a:hover{border-bottom-left-radius:3px;border-top-left-radius:3px}ul.oembedall-repo-stats li:last-child a:hover{border-bottom-right-radius:3px;border-top-right-radius:3px}span.oembedall-closehide{background-color:#aaa;border-radius:2px;cursor:pointer;margin-right:3px}div.oembedall-container{margin-top:5px;text-align:left}.oembedall-ljuser{font-weight:700}.oembedall-ljuser img{vertical-align:bottom;border:0;padding-right:1px}.oembedall-stoqembed{border-bottom:1px dotted #999;float:left;overflow:hidden;width:730px;line-height:1;background:#FFF;color:#000;font-family:Arial,Liberation Sans,DejaVu Sans,sans-serif;font-size:80%;text-align:left;margin:0;padding:0}.oembedall-stoqembed a{color:#07C;text-decoration:none;margin:0;padding:0}.oembedall-stoqembed a:hover{text-decoration:underline}.oembedall-stoqembed a:visited{color:#4A6B82}.oembedall-stoqembed h3{font-family:Trebuchet MS,Liberation Sans,DejaVu Sans,sans-serif;font-size:130%;font-weight:700;margin:0;padding:0}.oembedall-stoqembed .oembedall-reputation-score{color:#444;font-size:120%;font-weight:700;margin-right:2px}.oembedall-stoqembed .oembedall-user-info{height:35px;width:185px}.oembedall-stoqembed .oembedall-user-info .oembedall-user-gravatar32{float:left;height:32px;width:32px}.oembedall-stoqembed .oembedall-user-info .oembedall-user-details{float:left;margin-left:5px;overflow:hidden;white-space:nowrap;width:145px}.oembedall-stoqembed .oembedall-question-hyperlink{font-weight:700}.oembedall-stoqembed .oembedall-stats{background:#EEE;margin:0 0 0 7px;padding:4px 7px 6px;width:58px}.oembedall-stoqembed .oembedall-statscontainer{float:left;margin-right:8px;width:86px}.oembedall-stoqembed .oembedall-votes{color:#555;padding:0 0 7px;text-align:center}.oembedall-stoqembed .oembedall-vote-count-post{font-size:240%;color:#808185;display:block;font-weight:700}.oembedall-stoqembed .oembedall-views{color:#999;padding-top:4px;text-align:center}.oembedall-stoqembed .oembedall-status{margin-top:-3px;padding:4px 0;text-align:center;background:#75845C;color:#FFF}.oembedall-stoqembed .oembedall-status strong{color:#FFF;display:block;font-size:140%}.oembedall-stoqembed .oembedall-summary{float:left;width:635px}.oembedall-stoqembed .oembedall-excerpt{line-height:1.2;margin:0;padding:0 0 5px}.oembedall-stoqembed .oembedall-tags{float:left;line-height:18px}.oembedall-stoqembed .oembedall-tags a:hover{text-decoration:none}.oembedall-stoqembed .oembedall-post-tag{background-color:#E0EAF1;border-bottom:1px solid #3E6D8E;border-right:1px solid #7F9FB6;color:#3E6D8E;font-size:90%;line-height:2.4;margin:2px 2px 2px 0;padding:3px 4px;text-decoration:none;white-space:nowrap}.oembedall-stoqembed .oembedall-post-tag:hover{background-color:#3E6D8E;border-bottom:1px solid #37607D;border-right:1px solid #37607D;color:#E0EAF1}.oembedall-stoqembed .oembedall-fr{float:right}.oembedall-stoqembed .oembedall-statsarrow{background-image:url(http://cdn.sstatic.net/stackoverflow/img/sprites.png?v=3);background-repeat:no-repeat;overflow:hidden;background-position:0 -435px;float:right;height:13px;margin-top:12px;width:7px}.oembedall-facebook1{border:1px solid #1A3C6C;padding:0;font:13.34px/1.4 verdana;width:500px}.oembedall-facebook2{background-color:#627add}.oembedall-facebook2 a{color:#e8e8e8;text-decoration:none}.oembedall-facebookBody{background-color:#fff;vertical-align:top;padding:5px}.oembedall-facebookBody .contents{display:inline-block;width:100%}.oembedall-facebookBody div img{float:left;margin-right:5px}div.oembedall-lanyard{-webkit-box-shadow:none;-webkit-transition-delay:0s;-webkit-transition-duration:.4000000059604645s;-webkit-transition-property:width;-webkit-transition-timing-function:cubic-bezier(0.42,0,.58,1);background-attachment:scroll;background-clip:border-box;background-color:transparent;background-image:none;background-origin:padding-box;border-width:0;box-shadow:none;color:#112644;display:block;float:left;font-family:'Trebuchet MS',Trebuchet,sans-serif;font-size:16px;height:253px;line-height:19px;margin:0;max-width:none;min-height:0;outline:#112644 0;overflow-x:visible;overflow-y:visible;padding:0;position:relative;text-align:left;vertical-align:baseline;width:804px}div.oembedall-lanyard .tagline{font-size:1.5em}div.oembedall-lanyard .wrapper{overflow:hidden;clear:both}div.oembedall-lanyard .split{float:left;display:inline}div.oembedall-lanyard .prominent-place .flag:active,div.oembedall-lanyard .prominent-place .flag:focus,div.oembedall-lanyard .prominent-place .flag:hover,div.oembedall-lanyard .prominent-place .flag:link,div.oembedall-lanyard .prominent-place .flag:visited{float:left;display:block;width:48px;height:48px;position:relative;top:-5px;margin-right:10px}div.oembedall-lanyard .place-context{font-size:.889em}div.oembedall-lanyard .prominent-place .sub-place{display:block}div.oembedall-lanyard .prominent-place{font-size:1.125em;line-height:1.1em;font-weight:400}div.oembedall-lanyard .main-date{color:#8CB4E0;font-weight:700;line-height:1.1}div.oembedall-lanyard .first{width:48.57%;margin:0 0 0 2.857%}.mermaid .label{color:#333}.node circle,.node polygon,.node rect{fill:#cde498;stroke:#13540c;stroke-width:1px}.edgePath .path{stroke:green;stroke-width:1.5px}.cluster rect{fill:#cdffb2;rx:40;stroke:#6eaa49;stroke-width:1px}.cluster text{fill:#333}.actor{stroke:#13540c;fill:#cde498}text.actor{fill:#000;stroke:none}.actor-line{stroke:grey}.messageLine0{stroke-width:1.5;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#333}.messageLine1{stroke-width:1.5;stroke-dasharray:"2 2";stroke:#333}#arrowhead{fill:#333}#crosshead path{fill:#333!important;stroke:#333!important}.messageText{fill:#333;stroke:none}.labelBox{stroke:#326932;fill:#cde498}.labelText,.loopText{fill:#000;stroke:none}.loopLine{stroke-width:2;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#326932}.note{stroke:#6eaa49;fill:#fff5ad}.noteText{fill:#000;stroke:none;font-family:'trebuchet ms',verdana,arial;font-size:14px}.section{stroke:none;opacity:.2}.section0,.section2{fill:#6eaa49}.section1,.section3{fill:#fff;opacity:.2}.sectionTitle0,.sectionTitle1,.sectionTitle2,.sectionTitle3{fill:#333}.sectionTitle{text-anchor:start;font-size:11px;text-height:14px}.grid .tick{stroke:lightgrey;opacity:.3;shape-rendering:crispEdges}.grid path{stroke-width:0}.today{fill:none;stroke:red;stroke-width:2px}.task{stroke-width:2}.taskText{text-anchor:middle;font-size:11px}.taskTextOutsideRight{fill:#000;text-anchor:start;font-size:11px}.taskTextOutsideLeft{fill:#000;text-anchor:end;font-size:11px}.taskText0,.taskText1,.taskText2,.taskText3{fill:#fff}.task0,.task1,.task2,.task3{fill:#487e3a;stroke:#13540c}.taskTextOutside0,.taskTextOutside1,.taskTextOutside2,.taskTextOutside3{fill:#000}.active0,.active1,.active2,.active3{fill:#cde498;stroke:#13540c}.activeText0,.activeText1,.activeText2,.activeText3{fill:#000!important}.done0,.done1,.done2,.done3{stroke:grey;fill:lightgrey;stroke-width:2}.doneText0,.doneText1,.doneText2,.doneText3{fill:#000!important}.crit0,.crit1,.crit2,.crit3{stroke:#f88;fill:red;stroke-width:2}.activeCrit0,.activeCrit1,.activeCrit2,.activeCrit3{stroke:#f88;fill:#cde498;stroke-width:2}.doneCrit0,.doneCrit1,.doneCrit2,.doneCrit3{stroke:#f88;fill:lightgrey;stroke-width:2;cursor:pointer;shape-rendering:crispEdges}.activeCritText0,.activeCritText1,.activeCritText2,.activeCritText3,.doneCritText0,.doneCritText1,.doneCritText2,.doneCritText3{fill:#000!important}.titleText{text-anchor:middle;font-size:18px;fill:#000}text{font-family:'trebuchet ms',verdana,arial;font-size:14px}html{height:100%}body{margin:0!important;padding:5px 20px 26px!important;background-color:#fff;font-family:"Lucida Grande","Segoe UI","Apple SD Gothic Neo","Malgun Gothic","Lucida Sans Unicode",Helvetica,Arial,sans-serif;font-size:.9em;overflow-x:hidden;overflow-y:auto}br,h1,h2,h3,h4,h5,h6{clear:both}hr.page{background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x;border:0;height:3px;padding:0}hr.underscore{border-top-style:dashed!important}body >:first-child{margin-top:0!important}img.plugin{box-shadow:0 1px 3px rgba(0,0,0,.1);border-radius:3px}iframe{border:0}figure{-webkit-margin-before:0;-webkit-margin-after:0;-webkit-margin-start:0;-webkit-margin-end:0}kbd{border:1px solid #aaa;-moz-border-radius:2px;-webkit-border-radius:2px;border-radius:2px;-moz-box-shadow:1px 2px 2px #ddd;-webkit-box-shadow:1px 2px 2px #ddd;box-shadow:1px 2px 2px #ddd;background-color:#f9f9f9;background-image:-moz-linear-gradient(top,#eee,#f9f9f9,#eee);background-image:-o-linear-gradient(top,#eee,#f9f9f9,#eee);background-image:-webkit-linear-gradient(top,#eee,#f9f9f9,#eee);background-image:linear-gradient(top,#eee,#f9f9f9,#eee);padding:1px 3px;font-family:inherit;font-size:.85em}.oembeded .oembed_photo{display:inline-block}img[data-echo]{margin:25px 0;width:100px;height:100px;background:url(http://www.open-std.org/jtc1/sc22/wg21/docs/papers/img/ajax.gif) center center no-repeat #fff}.spinner{display:inline-block;width:10px;height:10px;margin-bottom:-.1em;border:2px solid rgba(0,0,0,.5);border-top-color:transparent;border-radius:100%;-webkit-animation:spin 1s infinite linear;animation:spin 1s infinite linear}.spinner:after{content:'';display:block;width:0;height:0;position:absolute;top:-6px;left:0;border:4px solid transparent;border-bottom-color:rgba(0,0,0,.5);-webkit-transform:rotate(45deg);transform:rotate(45deg)}@-webkit-keyframes spin{to{-webkit-transform:rotate(360deg)}}@keyframes spin{to{transform:rotate(360deg)}}p.toc{margin:0!important}p.toc ul{padding-left:10px}p.toc>ul{padding:10px;margin:0 10px;display:inline-block;border:1px solid #ededed;border-radius:5px}p.toc li,p.toc ul{list-style-type:none}p.toc li{width:100%;padding:0;overflow:hidden}p.toc li a::after{content:"."}p.toc li a:before{content:"• "}p.toc h5{text-transform:uppercase}p.toc .title{float:left;padding-right:3px}p.toc .number{margin:0;float:right;padding-left:3px;background:#fff;display:none}input.task-list-item{margin-left:-1.62em}.markdown{font-family:"Hiragino Sans GB","Microsoft YaHei",STHeiti,SimSun,"Lucida Grande","Lucida Sans Unicode","Lucida Sans",'Segoe UI',AppleSDGothicNeo-Medium,'Malgun Gothic',Verdana,Tahoma,sans-serif;padding:20px}.markdown a{text-decoration:none;vertical-align:baseline}.markdown a:hover{text-decoration:underline}.markdown h1{font-size:2.2em;font-weight:700;margin:1.5em 0 1em}.markdown h2{font-size:1.8em;font-weight:700;margin:1.275em 0 .85em}.markdown h3{font-size:1.6em;font-weight:700;margin:1.125em 0 .75em}.markdown h4{font-size:1.4em;font-weight:700;margin:.99em 0 .66em}.markdown h5{font-size:1.2em;font-weight:700;margin:.855em 0 .57em}.markdown h6{font-size:1em;font-weight:700;margin:.75em 0 .5em}.markdown h1+p,.markdown h1:first-child,.markdown h2+p,.markdown h2:first-child,.markdown h3+p,.markdown h3:first-child,.markdown h4+p,.markdown h4:first-child,.markdown h5+p,.markdown h5:first-child,.markdown h6+p,.markdown h6:first-child{margin-top:0}.markdown hr{border:1px solid #ccc}.markdown p{margin:1em 0;word-wrap:break-word}.markdown ol{list-style-type:decimal}.markdown li{display:list-item;line-height:1.4em}.markdown blockquote{margin:1em 20px}.markdown blockquote>:first-child{margin-top:0}.markdown blockquote>:last-child{margin-bottom:0}.markdown blockquote cite:before{content:'\2014 \00A0'}.markdown .code{border-radius:3px;word-wrap:break-word}.markdown pre{border-radius:3px;word-wrap:break-word;border:1px solid #ccc;overflow:auto;padding:.5em}.markdown pre code{border:0;display:block}.markdown pre>code{font-family:Consolas,Inconsolata,Courier,monospace;font-weight:700;white-space:pre;margin:0}.markdown code{border-radius:3px;word-wrap:break-word;border:1px solid #ccc;padding:0 5px;margin:0 2px}.markdown img{max-width:100%}.markdown mark{color:#000;background-color:#fcf8e3}.markdown table{padding:0;border-collapse:collapse;border-spacing:0;margin-bottom:16px}.markdown table tr td,.markdown table tr th{border:1px solid #ccc;margin:0;padding:6px 13px}.markdown table tr th{font-weight:700}.markdown table tr th>:first-child{margin-top:0}.markdown table tr th>:last-child{margin-bottom:0}.markdown table tr td>:first-child{margin-top:0}.markdown table tr td>:last-child{margin-bottom:0}@import url(http://fonts.googleapis.com/css?family=Roboto+Condensed:300italic,400italic,700italic,400,300,700);.haroopad{padding:20px;color:#222;font-size:15px;font-family:"Roboto Condensed",Tauri,"Hiragino Sans GB","Microsoft YaHei",STHeiti,SimSun,"Lucida Grande","Lucida Sans Unicode","Lucida Sans",'Segoe UI',AppleSDGothicNeo-Medium,'Malgun Gothic',Verdana,Tahoma,sans-serif;background:#fff;line-height:1.6;-webkit-font-smoothing:antialiased}.haroopad a{color:#3269a0}.haroopad a:hover{color:#4183c4}.haroopad h2{border-bottom:1px solid #e6e6e6}.haroopad h6{color:#777}.haroopad hr{border:1px solid #e6e6e6}.haroopad blockquote>code,.haroopad h1>code,.haroopad h2>code,.haroopad h3>code,.haroopad h4>code,.haroopad h5>code,.haroopad h6>code,.haroopad li>code,.haroopad p>code,.haroopad td>code{font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;font-size:85%;background-color:rgba(0,0,0,.02);padding:.2em .5em;border:1px solid #efefef}.haroopad pre>code{font-size:1em;letter-spacing:-1px;font-weight:700}.haroopad blockquote{border-left:4px solid #e6e6e6;padding:0 15px;color:#777}.haroopad table{background-color:#fafafa}.haroopad table tr td,.haroopad table tr th{border:1px solid #e6e6e6}.haroopad table tr:nth-child(2n){background-color:#f2f2f2}.hljs{display:block;overflow-x:auto;padding:.5em;background:#fdf6e3;color:#657b83;-webkit-text-size-adjust:none}.diff .hljs-header,.hljs-comment,.hljs-doctype,.hljs-javadoc,.hljs-pi,.lisp .hljs-string{color:#93a1a1}.css .hljs-tag,.hljs-addition,.hljs-keyword,.hljs-request,.hljs-status,.hljs-winutils,.method,.nginx .hljs-title{color:#859900}.hljs-command,.hljs-dartdoc,.hljs-hexcolor,.hljs-link_url,.hljs-number,.hljs-phpdoc,.hljs-regexp,.hljs-rules .hljs-value,.hljs-string,.hljs-tag .hljs-value,.tex .hljs-formula{color:#2aa198}.css .hljs-function,.hljs-built_in,.hljs-chunk,.hljs-decorator,.hljs-id,.hljs-identifier,.hljs-localvars,.hljs-title,.vhdl .hljs-literal{color:#268bd2}.hljs-attribute,.hljs-class .hljs-title,.hljs-constant,.hljs-link_reference,.hljs-parent,.hljs-type,.hljs-variable,.lisp .hljs-body,.smalltalk .hljs-number{color:#b58900}.css .hljs-pseudo,.diff .hljs-change,.hljs-attr_selector,.hljs-cdata,.hljs-header,.hljs-pragma,.hljs-preprocessor,.hljs-preprocessor .hljs-keyword,.hljs-shebang,.hljs-special,.hljs-subst,.hljs-symbol,.hljs-symbol .hljs-string{color:#cb4b16}.hljs-deletion,.hljs-important{color:#dc322f}.hljs-link_label{color:#6c71c4}.tex .hljs-formula{background:#eee8d5}.MathJax_Hover_Frame{border-radius:.25em;-webkit-border-radius:.25em;-moz-border-radius:.25em;-khtml-border-radius:.25em;box-shadow:0 0 15px #83A;-webkit-box-shadow:0 0 15px #83A;-moz-box-shadow:0 0 15px #83A;-khtml-box-shadow:0 0 15px #83A;border:1px solid #A6D!important;display:inline-block;position:absolute}.MathJax_Hover_Arrow{position:absolute;width:15px;height:11px;cursor:pointer}#MathJax_About{position:fixed;left:50%;width:auto;text-align:center;border:3px outset;padding:1em 2em;background-color:#DDD;color:#000;cursor:default;font-family:message-box;font-size:120%;font-style:normal;text-indent:0;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;z-index:201;border-radius:15px;-webkit-border-radius:15px;-moz-border-radius:15px;-khtml-border-radius:15px;box-shadow:0 10px 20px gray;-webkit-box-shadow:0 10px 20px gray;-moz-box-shadow:0 10px 20px gray;-khtml-box-shadow:0 10px 20px gray;filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}.MathJax_Menu{position:absolute;background-color:#fff;color:#000;width:auto;padding:2px;border:1px solid #CCC;margin:0;cursor:default;font:menu;text-align:left;text-indent:0;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;z-index:201;box-shadow:0 10px 20px gray;-webkit-box-shadow:0 10px 20px gray;-moz-box-shadow:0 10px 20px gray;-khtml-box-shadow:0 10px 20px gray;filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}.MathJax_MenuItem{padding:2px 2em;background:0 0}.MathJax_MenuArrow{position:absolute;right:.5em;color:#666}.MathJax_MenuActive .MathJax_MenuArrow{color:#fff}.MathJax_MenuArrow.RTL{left:.5em;right:auto}.MathJax_MenuCheck{position:absolute;left:.7em}.MathJax_MenuCheck.RTL{right:.7em;left:auto}.MathJax_MenuRadioCheck{position:absolute;left:1em}.MathJax_MenuRadioCheck.RTL{right:1em;left:auto}.MathJax_MenuLabel{padding:2px 2em 4px 1.33em;font-style:italic}.MathJax_MenuRule{border-top:1px solid #CCC;margin:4px 1px 0}.MathJax_MenuDisabled{color:GrayText}.MathJax_MenuActive{background-color:Highlight;color:HighlightText}.MathJax_Menu_Close{position:absolute;width:31px;height:31px;top:-15px;left:-15px}#MathJax_Zoom{position:absolute;background-color:#F0F0F0;overflow:auto;display:block;z-index:301;padding:.5em;border:1px solid #000;margin:0;font-weight:400;font-style:normal;text-align:left;text-indent:0;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;box-shadow:5px 5px 15px #AAA;-webkit-box-shadow:5px 5px 15px #AAA;-moz-box-shadow:5px 5px 15px #AAA;-khtml-box-shadow:5px 5px 15px #AAA;filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}#MathJax_ZoomOverlay{position:absolute;left:0;top:0;z-index:300;display:inline-block;width:100%;height:100%;border:0;padding:0;margin:0;background-color:#fff;opacity:0;filter:alpha(opacity=0)}#MathJax_ZoomFrame{position:relative;display:inline-block;height:0;width:0}#MathJax_ZoomEventTrap{position:absolute;left:0;top:0;z-index:302;display:inline-block;border:0;padding:0;margin:0;background-color:#fff;opacity:0;filter:alpha(opacity=0)}.MathJax_Preview{color:#888}#MathJax_Message{position:fixed;left:1px;bottom:2px;background-color:#E6E6E6;border:1px solid #959595;margin:0;padding:2px 8px;z-index:102;color:#000;font-size:80%;width:auto;white-space:nowrap}#MathJax_MSIE_Frame{position:absolute;top:0;left:0;width:0;z-index:101;border:0;margin:0;padding:0}.MathJax_Error{color:#C00;font-style:italic}footer{position:fixed;font-size:.8em;text-align:right;bottom:0;margin-left:-25px;height:20px;width:100%}</style>
</head>
<body class="markdown haroopad">
<p><strong>Document number: P0567r1</strong><br><strong>Date: 2017-06-19</strong><br><strong>Project: SG1, SG14</strong><br><strong>Authors: Gordon Brown, Ruyman Reyes, Michael Wong</strong><br><strong>Emails: gordon@codeplay.com, ruyman@codeplay.com, michael@codeplay.com</strong><br><strong>Reply to: michael@codeplay.com, gordon@codeplay.com</strong></p><h1 id="asynchronous-managed-pointer-for-heterogeneous-and-distributed-computing"><a name="asynchronous-managed-pointer-for-heterogeneous-and-distributed-computing" href="p0567r1.html#asynchronous-managed-pointer-for-heterogeneous-and-distributed-computing"></a>Asynchronous Managed Pointer for Heterogeneous and Distributed Computing</h1><h2 id="revision-history"><a name="revision-history" href="p0567r1.html#revision-history"></a>Revision History</h2><h3 id="p0567r0-->-p0567r1:"><a name="p0567r0-->-p0567r1:" href="p0567r1.html#p0567r0--&gt;-p0567r1:"></a>P0567r0 -&gt; P0567r1:</h3><ul>
<li>A new section has been added to describe the requirements of the paper.</li><li>Corrections and updates have been made to the example code.</li><li>The synopsis has been extended to cover the requirements for the <strong>executor</strong> and <strong>future</strong> types.</li><li>Restriction on having only one device within a system capable of performing sycnhornisation operations has been removed.</li><li>Implicit synchornisation removed as future work for now as it requires static reflection.</li><li>The <code>managed_ptr</code> now interfaces with an <strong>executor</strong> rather than an <strong>execution context</strong>.</li><li>The <code>managed_ptr</code> now has an <strong>executor</strong> associated with it which can be retrieved with the member function <code>get_local_execution_context()</code>.</li><li>The <code>managed_ptr</code> synchronization member function <code>get()</code> and the <strong>executor</strong> class synchronization member functions <code>get()</code>, <code>then_get()</code>, <code>put()</code> and <code>then_put()</code> have been removed, leaving only the global synchronization functions <code>get()</code>, <code>then_get()</code>, <code>put()</code> and <code>then_put()</code>.</li><li>The <code>managed_ptr</code> no longer has a size associated with it, instead it it represents a pointer to a single value in the same way a <code>std::shared_ptr</code> does.</li><li>The <code>managed_ptr</code> member alias <code>future_type</code> has been removed and the global synchronization functions <code>get()</code>, <code>then_get()</code>, <code>put()</code> and <code>then_put()</code> now return <code>executor_future_t</code>.</li><li>The <code>managed_ptr</code> constructors have been altered so there is now only two constructors, one that initialises with an allocator, that is defaulted to the allocator associated with the associated <strong>executor</strong> and one that takes an raw pointer.</li><li>The <code>managed_ptr</code> pointer and dereference operators have been specialised for const instantiations.</li><li>The <code>managed_ptr</code> now has the member function <code>is_allocated()</code> to query if the <code>managed_ptr</code> has been allocated on a particular execution context.</li><li>The compile-time traits <code>can_put_v</code>, <code>can_get_v</code>, <code>can_sync_v</code>, <code>can_allocate_v</code> and <code>can_deallocate_v</code> have been added for querying an executors capabilities with regard to data movement.</li><li>The <code>managed_ptr</code> member function <code>is_accessible</code> now takes an <strong>executor</strong> parameter with a default argument allowing you to query if the <code>managed_ptr</code> intance is accessible in another execution context.</li><li>The global synchronization functions <code>get()</code> and <code>then_get()</code> no longer take an <strong>executor</strong> parameter, as the associated <strong>executor</strong> can be inferred from the <code>managed_ptr</code> parameters.</li><li>The global synchronization operations <code>sync</code> and <code>then_sync</code> which take an <strong>execution channel</strong> have been added.</li><li>Add explicit allocation and deallocation via global allocation functions <code>allocate</code>, <code>then_allocate</code>, <code>deallocate</code> and <code>then_deallocate</code>.</li></ul><h2 id="feedback-from-p0567r0,-2017-01-30"><a name="feedback-from-p0567r0,-2017-01-30" href="p0567r1.html#feedback-from-p0567r0,-2017-01-30"></a>Feedback from P0567r0, 2017-01-30</h2><p>Much valuable feedback was given since the last revision of this paper, this section will identify the issues that were raised and points to their respective solutions.</p><h3 id="read-only-pointers"><a name="read-only-pointers" href="p0567r1.html#read-only-pointers"></a>Read-only pointers</h3><p>It was suggested that the <code>managed_ptr</code> should be capable of providing read-only access, where write access is restricted, this can be very useful as it allows an implementation to make use of read-only partitions of memory which are often more efficient to access. This is now supported in this paper and is described in section 3.3.</p><h3 id="allocation-of-managed-memory"><a name="allocation-of-managed-memory" href="p0567r1.html#allocation-of-managed-memory"></a>Allocation of managed memory</h3><p>There were many questions regarding how the how and when memory is allocated for a <code>managed_ptr</code> instance and what happens on an allocation failure. Section 3.3.4 has been added which describes these behaviours.</p><h3 id="optimising-synchronization-between-execution-contexts"><a name="optimising-synchronization-between-execution-contexts" href="p0567r1.html#optimising-synchronization-between-execution-contexts"></a>Optimising synchronization between execution contexts</h3><p>It was suggested that it be possible for an implementation to optimise synchronisation of a <code>managed_ptr</code> between specific executors rather than having to synchronise via a host executor. A solution that was being discussed but didn’t make it into the first revision of the paper was the concept of channels. This is now supported in this paper and is described in section 3.5.</p><h3 id="discuss-memory-access-in-terms-of-side-effects"><a name="discuss-memory-access-in-terms-of-side-effects" href="p0567r1.html#discuss-memory-access-in-terms-of-side-effects"></a>Discuss memory access in terms of side effects</h3><p>It was suggested that this proposal should describe memory access in terms of visible sided effects rather than caching. This has been introduced as part of the requirement for supporting different memory architectures and the paper has been updated to reflect this.</p><h3 id="host-based-and-remote-execution-contexts"><a name="host-based-and-remote-execution-contexts" href="p0567r1.html#host-based-and-remote-execution-contexts"></a>Host based and remote execution contexts</h3><p>It was asked what would happen if <code>malloc()</code> were to be called on a GPGPU. The answer to this is that dynamic allocation cannot be supported for the general case as many GPUs do not support this due to hardware limitations. There are some GPUs which do support dynamic allocation such as devices supporting CUDA 2.x and above, however, this is not the common case. This question of <em>execution context</em> capabilities is described in section 3.3.5.</p><h3 id="supporting-systems-with-unified-address-spaces"><a name="supporting-systems-with-unified-address-spaces" href="p0567r1.html#supporting-systems-with-unified-address-spaces"></a>Supporting systems with unified address spaces</h3><p>It was asked if the <code>managed_ptr</code> could allow concurrent access to memory from different execution contexts, this can be very important for systems which have regions of memory shared across discrete devices. This was discussed however did not make it into the first draft of the paper as a solution had not yet been reached. The current proposed solution is described in section 4.1 as future work.</p><h2 id="1.-introduction"><a name="1.-introduction" href="p0567r1.html#1.-introduction"></a>1. Introduction</h2><h3 id="1.1.-summary"><a name="1.1.-summary" href="p0567r1.html#1.1.-summary"></a>1.1. Summary</h3><p>This paper proposes an extension to the unified interface for execution proposal [1] to facilitate the management and synchronisation of a memory allocation across multiple memory region(s). This addition is in the form of the class template <code>managed_ptr</code>; similar to the <code>std::shared_ptr</code> but with the addition that it can share its memory allocation across the memory region of it’s host executor where it is constructed and the memory region(s) of one or more other executors.</p><p>The aim of this paper is to begin an exploratory work into designing a unified interface for data movement. There are many different architectures and data flow models to consider when designing such an interface so it is expected that this paper will serve only as a starting point.</p><h3 id="1.2.-motivation"><a name="1.2.-motivation" href="p0567r1.html#1.2.-motivation"></a>1.2. Motivation</h3><p>In non-heterogeneous or non-distributed systems, there is typically a single device: a CPU with a single memory region or an area of addressable memory. In contrast, heterogeneous and distributed systems have multiple devices with shared or discrete memory regions.</p><p>There are several key points to consider when addressing heterogeneous and distributed systems:</p><ul>
<li>Each device within a heterogeneous or distributed system can potentially require code compiled for a different ISA.</li><li>Each device within a heterogeneous or distributed system can have shared or discrete regions of memory.</li><li>Each heterogeneous or distributed systems can have different forms of communications between the devices; including shared memory, bus or network.</li><li>Each device within a heterogeneous or distributed system can have varying levels of functionality; not all devices can function as fully featured C++ threads.</li></ul><p>As the act of dispatching work to a remote device to be executed was once only a problem for third party APIs and so too was the act of moving data to those devices for computations to be performed on. However, now that C++ is progressing towards a unified interface for execution [1] the act of moving data is now a problem for C++ to solve as well. The act of moving data to a remote device is very tightly coupled with the work being performed on said remote device. This means that this unified interface for data movement must also be tightly coupled with the unified interface for execution.</p><p>For a more in-depth analysis of the requirements for supporting heterogeneous systems in C++ see P0687r0: Data Movement in C++ [13].</p><p>The managed memory class will represent a memory allocation that may be available in one of many memory regions within a system throughout a program’s execution. For the purposes of this paper, we will refer to such a memory allocation as a managed memory allocation as it describes a memory allocation that is accessible consistently across multiple memory regions. With this requirement comes the possibility that a memory region on a given device may not have the most recently modified copy of a managed memory allocation, therefore requiring synchronisation to move the data.</p><h3 id="1.3.-influence"><a name="1.3.-influence" href="p0567r1.html#1.3.-influence"></a>1.3. Influence</h3><p>This proposal is influenced by many heterogeneous and distributed programming models; including SYCL [2], HPX [3], KoKKos [4], Raja [5], HAM-Offload [9] and MYO [11].</p><p>This approach is also heavily influenced by the proposal for a unified interface for execution as the interface proposed in this paper interacts directly with this.</p><h2 id="2.-requirements-/-design-goals"><a name="2.-requirements-/-design-goals" href="p0567r1.html#2.-requirements-/-design-goals"></a>2. Requirements / Design Goals</h2><p>When attempting to standardise a unified interface for data movement there are many different aspects which need to be considered. These come from both the various architectures that this interface aims to abstract and the various data flow models which this interface aims to provide.</p><ol>
<li>Must support different memory architectures</li><li>Must support different levels of synchronisation</li><li>Must support different data flow models</li><li>Must integrate seamlessly with executors</li><li>Must be interoperable between executor implementations</li><li>Must allow optimisation of data movement between devices</li><li>Must abstract device capabilities</li></ol><p>This paper in it’s current state aims to satisfy [1], [3], [4], [5], [6], [7], while [2] is still being developed.</p><h3 id="2.1.-must-support-different-memory-architectures"><a name="2.1.-must-support-different-memory-architectures" href="p0567r1.html#2.1.-must-support-different-memory-architectures"></a>2.1. Must support different memory architectures</h3><p>In non-heterogeneous or non-distributed systems, there is typically a single device: a host CPU with a single memory region or an area of addressable memory. In contrast, heterogeneous and distributed systems have multiple devices (including the host CPU) often with their own discrete memory regions. A device in this respect can be any architecture that exists within a system that is C++ programmable; this can include CPUs, GPGPUs, APUs, FPGAs, DSPs, NUMA nodes, I/O devices and other forms of accelerators.</p><p>These memory regions can be categorised into two groups.</p><ul>
<li>The first group represents all the memory regions of systems with a single unified address space, that is a single area of addressable memory that is accessible across multiple devices. This can optionally be supported in hardware by devices having the same physical memory or in software by having a cache coherency layer accessing a shared virtual address space.</li><li>The second group represents all the memory regions of systems with multiple address spaces, therefore having separate discrete areas of addressable memory, often in different physical memory.</li></ul><p>A unified interface needs to be capable of supporting both of these kinds of memory architectures in such a way that any requirements for cache coherency is abstracted by the interface and associated coherency model.</p><h3 id="2.2.-must-support-different-levels-of-synchronisation"><a name="2.2.-must-support-different-levels-of-synchronisation" href="p0567r1.html#2.2.-must-support-different-levels-of-synchronisation"></a>2.2. Must support different levels of synchronisation</h3><p>Different memory architectures, both unified and discrete; may support granularity at different levels. This can either be at the coarse-grained level; where synchronization between memory regions is performed at the execution function level, or this can be at the fine-grained level; where synchronization between memory regions is performed at the instruction level, allowing access to memory from different devices concurrently, using atomics to specify read and write order.</p><p>A unified interface needs to be capable of supporting both these levels of synchronisation.</p><h3 id="2.3.-must-support-different-data-flow-models"><a name="2.3.-must-support-different-data-flow-models" href="p0567r1.html#2.3.-must-support-different-data-flow-models"></a>2.3. Must support different data flow models</h3><p>There are many different ways for a programming model to represent the data required for a computation and how that data is made available on a particular device. This paper will use the term <strong>data-flow model</strong> to refer to a model which describes what a computation’s data dependencies are, where they are required to be accessed and when they are to be made available.</p><p>This paper identifies four kinds of data-flow models which this proposal must be capable of supporting. These are referred to as <strong>explicit data-flow models</strong>, <strong>chained data-flow models</strong>, <strong>implicit data-flow models</strong> and <strong>graph-based data-flow models</strong>.</p><p>An <strong>explicit data-flow model</strong> is one which allows users to manually specify the point at which a data dependency is made available to a computation via an API. These APIs can generally be synchronous or asynchronous, providing some form of synchronisation primitive which can be used to signal when the data dependency is available on the target device. An example of this could be an explicit copy operation:</p><pre class="cpp hljs"><code class="cpp" data-origin="<pre><code class=&quot;cpp&quot;>copy(ptr, contextA, contextB);
execute(contextB, func(ptr));
</code></pre>">copy(ptr, contextA, contextB);
execute(contextB, func(ptr));
</code></pre><p>A <strong>chained data-flow model</strong> is an extension of an explicit data-flow mode, where the synchronisation primitives also provide the capability of specifying further data dependency requirements or launching a computation when the data dependency is available on the target device. This kind of data-flow models are often coupled very tightly with the computation. An example of this could be future based continuations:</p><pre class="cpp hljs"><code class="cpp" data-origin="<pre><code class=&quot;cpp&quot;>copy(ptr, contextA, contextB)
  then_execute(contextB, func(ptr));
</code></pre>">copy(ptr, contextA, contextB)
  then_execute(contextB, func(ptr));
</code></pre><p>An <strong>implicit data-flow model</strong> is one which allows data dependencies to be described by simply passing those data dependencies to a computation and having them implicitly made available on the target device. This kind of data-flow models can feel very natural for users, however, they can involve some with limitations to some data-flow optimisation such as prefetching or double buffering. An example of this could be a pointer that can be passed directly to a computation:</p><pre class="cpp hljs"><code class="cpp" data-origin="<pre><code class=&quot;cpp&quot;>execute(contextB, func(ptr));
</code></pre>">execute(contextB, func(ptr));
</code></pre><p>A <strong>graph-based data-flow</strong> is one which allows data dependencies to be described by a high-level graph; often in some form of DSL or other graph format. This kind of data-flow models, as they have access to a greater amount of information can often perform optimisations to the data dependency representation. As with the chained data-flow model the graph-based data-flow models are also coupled tightly with computation. An example of this could be a compile-time DSL that evaluates the parameters of an expression:</p><pre class="cpp hljs"><code class="cpp" data-origin="<pre><code class=&quot;cpp&quot;>eval(contextB, y = a * x + y);
</code></pre>">eval(contextB, y = a * x + y);
</code></pre><p>The proposal must provide an interface which can provide a foundation for all four of these data-flow models.</p><h3 id="2.4.-must-integrate-seamlessly-with-executors"><a name="2.4.-must-integrate-seamlessly-with-executors" href="p0567r1.html#2.4.-must-integrate-seamlessly-with-executors"></a>2.4. Must integrate seamlessly with executors</h3><p>As data movement is tightly coupled with execution, it is necessary for a unified interface for data movement to be integrated with the unified interface for execution. This means such a unified interface must integrate seamlessly with the current design philosophy of executors. It must be compatible with the range of control structures which the executor abstraction supports and must support the range of platforms which executors can target.</p><p>At the same time, a unified interface for data movement must exist at a high level of abstraction and must avoid introducing too many requirements on executor implementations, in order to avoid introducing complex requirements for heterogeneous or distributed memory architectures into C++.</p><h3 id="2.5.-must-be-interoperable-between-executor-implementations"><a name="2.5.-must-be-interoperable-between-executor-implementations" href="p0567r1.html#2.5.-must-be-interoperable-between-executor-implementations"></a>2.5. Must be interoperable between executor implementations</h3><p>The unified interface for execution will have may different implementation which target different platforms and therefore a unified interface for data movement would too require this range of implementations.</p><p>It’s important therefore that a unified interface for data movement be interoperable between different executor implementations, it must be possible to synchronise data between the memory region of one executor implementation and another.</p><h3 id="2.6.-must-allow-optimisation-of-data-movement-between-devices"><a name="2.6.-must-allow-optimisation-of-data-movement-between-devices" href="p0567r1.html#2.6.-must-allow-optimisation-of-data-movement-between-devices"></a>2.6. Must allow optimisation of data movement between devices</h3><p>A unified interface for data movement must provide interoperability between implementations, however, this will likely be inefficient as it will likely require a middle man stage that facilitates the required operations of each implementation.</p><p>Therefore it’s important that a unified interface for data movement provide a facility for customising data movement between particular memory regions in order to optimise those operations rather than relying on a generic middle man.</p><h3 id="2.7.-must-abstract-device-capabilities"><a name="2.7.-must-abstract-device-capabilities" href="p0567r1.html#2.7.-must-abstract-device-capabilities"></a>2.7. Must abstract device capabilities</h3><p>Many heterogeneous architectures such as GPGPUs, DSPs or FPGAs have considerable restrictions on the code that is executed on the compared to that of a CPU, such as no capability to dynamically allocate memory or signal directly with other devices during execution and the level of forward progress guarantees the device can provide. This means that a unified interface for data movement needs to take into consideration these restrictions in the design of how memory on devices is allocated and synchronised.</p><p>A typical example of this is that a CPU cluster would have no problem allocating a <code>managed_ptr</code> on any one of its nodes and performing synchronisation operations on any node, whereas with a typical GPU all allocation and synchronisation must be done from a host CPU device prior to execution.</p><h2 id="3.-proposed-additions"><a name="3.-proposed-additions" href="p0567r1.html#3.-proposed-additions"></a>3. Proposed Additions</h2><h3 id="3.1.-header-``-synopis"><a name="3.1.-header-``-synopis" href="p0567r1.html#3.1.-header-``-synopis"></a>3.1. Header <code>&lt;execution&gt;</code> synopis</h3><pre class="cpp hljs"><code class="cpp" data-origin="<pre><code class=&quot;cpp&quot;>namespace std {
namespace experimental {
inline namespace concurrency_v2 {
namespace execution {

/* extensions to executor classes */
class executor {
  ...

  /* aliases */
  using executor_memory_allocator_type = __executor_memory_allocator_type__;

  /* member functions */
  executor_memory_allocator_type executor_memory_allocator() const;

  ...
};

/* managed_ptr class template */
template &amp;lt;typename T&amp;gt;
class managed_ptr {
public:

  /* aliases */
  using value_type              = __undefined_attributes__ T;
  using pointer                 = value_type *;
  using const_pointer           = const value_type *;
  using reference               = value_type &amp;amp;;
  using const_reference         = const value_type &amp;amp;;
  using host_executor_type      = __host_executor_type__;
  using executor_allocator_type = host_executor_type::executor_memory_allocator_type;

  /* constructors */
  managed_ptr(pointer); // (1)
  template &amp;lt;typename Allocator&amp;gt;
  managed_ptr(Allocator allocator = executor_allocator_type{}); // (2)

  /* special member functions */
  managed_ptr(const managed_ptr &amp;amp;);
  managed_ptr(managed_ptr &amp;amp;&amp;amp;);
  managed_ptr &amp;amp;operator=(const managed_ptr &amp;amp;);
  managed_ptr &amp;amp;operator=(managed_ptr &amp;amp;&amp;amp;);
  ~managed_ptr();

  /* member functions */
  host_executor_type &amp;amp;executor() const;
  template &amp;lt;typename Executor&amp;gt;
  bool is_allocated(Executor = host_executor_type{}) const;
  template &amp;lt;typename Executor&amp;gt;
  bool is_accessible(Executor = host_executor_type{}) const;

  /* operators of const T instantiation */
  const_reference operator*() const;
  const_pointer operator-&amp;gt;() const;

  /* operators of non-const T instantiation */
  reference operator*() const;
  pointer operator-&amp;gt;() const;
};

/* extended retuirements for executor_future_t */
template &amp;lt;typename T&amp;gt;
class executor_future_t {
  ...

  /* synchronization member functions */
  template &amp;lt;typename Executor, typename... ManagedPtrN&amp;gt;
  future_type_t&amp;lt;void&amp;gt; put(Executor, ManagedPtrN...);
  template &amp;lt;typename... ManagedPtrN&amp;gt;
  future_type_t&amp;lt;void&amp;gt; get(ManagedPtrTN...);
  template &amp;lt;typename SynchronizationChannel, typename SrcExecutor,
            typename DestExecutor, typename... ManagedPtrN&amp;gt;
  future_type_t&amp;lt;void&amp;gt;
  sync(SynchronizationChannel = __default_synchronization_channel__{},
       SrcExecutor, DestExecutor, ManagedPtrN...);

  /* allocation member functions */
  template &amp;lt;typename Executor, typename... ManagedPtrN&amp;gt;
  future_type_t&amp;lt;void&amp;gt; allocate(Executor, ManagedPtrN...);
  template &amp;lt;typename Executor, typename... ManagedPtrN&amp;gt;
  future_type_t&amp;lt;void&amp;gt; deallocate(Executor, ManagedPtrN...);

  ...
};

/* synchronization functions */
template &amp;lt;typename Executor, typename... ManagedPtrN&amp;gt;
future_type_t&amp;lt;void&amp;gt; put(Executor, ManagedPtrN...);
template &amp;lt;typename Executor, typename Predicate, typename... ManagedPtrN&amp;gt;
future_type_t&amp;lt;void&amp;gt; then_put(Executor, Predicate, ManagedPtrN...);
template &amp;lt;typename... ManagedPtrN&amp;gt;
future_type_t&amp;lt;void&amp;gt; get(ManagedPtrTN...);
template &amp;lt;typename Predicate, typename... ManagedPtrN&amp;gt;
future_type_t&amp;lt;void&amp;gt; then_get(Predicate, ManagedPtrN...);
template &amp;lt;typename SynchronizationChannel, typename SrcExecutor,
          typename DestExecutor, typename... ManagedPtrN&amp;gt;
future_type_t&amp;lt;void&amp;gt;
sync(SynchronizationChannel = __default_synchronization_channel__{},
     SrcExecutor, DestExecutor, ManagedPtrN...);
template &amp;lt;typename SynchronizationChannel, typename SrcExecutor,
          typename DestExecutor, typename Predicate, typename... ManagedPtrN&amp;gt;
future_type_t&amp;lt;void&amp;gt;
then_sync(SynchronizationChannel = __default_synchronization_channel__{},
          SrcExecutor, DestExecutor, Predicate, ManagedPtrN...);

/* allocation functions */
template &amp;lt;typename Executor, typename... ManagedPtrN&amp;gt;
future_type_t&amp;lt;void&amp;gt; allocate(Executor, ManagedPtrN...);
template &amp;lt;typename Executor, typename Predicate, typename... ManagedPtrN&amp;gt;
future_type_t&amp;lt;void&amp;gt; then_allocate(Executor, Predicate, ManagedPtrN...);
template &amp;lt;typename Executor, typename... ManagedPtrN&amp;gt;
future_type_t&amp;lt;void&amp;gt; deallocate(Executor, ManagedPtrN...);
template &amp;lt;typename Executor, typename Predicate, typename... ManagedPtrN&amp;gt;
future_type_t&amp;lt;void&amp;gt; then_deallocate(Executor, Predicate,
                                              ManagedPtrN...);

/* executor traits */
template&amp;lt;class T&amp;gt; struct can_put;
template&amp;lt;class T&amp;gt; struct can_get;
template&amp;lt;class T&amp;gt; struct can_sync;
template&amp;lt;class T&amp;gt; struct can_allocate;
template&amp;lt;class T&amp;gt; struct can_deallocate;
template&amp;lt;class T&amp;gt; constexpr bool can_put_v = can_put&amp;lt;T&amp;gt;::value;
template&amp;lt;class T&amp;gt; constexpr bool can_get_v = can_get&amp;lt;T&amp;gt;::value;
template&amp;lt;class T&amp;gt; constexpr bool can_sync_v = can_sync&amp;lt;T&amp;gt;::value;
template&amp;lt;class T&amp;gt; constexpr bool can_allocate_v = can_allocate&amp;lt;T&amp;gt;::value;
template&amp;lt;class T&amp;gt; constexpr bool can_deallocate_v = can_deallocate&amp;lt;T&amp;gt;::value;

}  // namespace execution
}  // namespace concurrency_v2
}  // namespace experimental
}  // namespace std
</code></pre>"><span class="hljs-keyword">namespace</span> <span class="hljs-built_in">std</span> {
<span class="hljs-keyword">namespace</span> experimental {
<span class="hljs-keyword">inline</span> <span class="hljs-keyword">namespace</span> concurrency_v2 {
<span class="hljs-keyword">namespace</span> execution {

<span class="hljs-comment">/* extensions to executor classes */</span>
<span class="hljs-keyword">class</span> executor {
  ...

  <span class="hljs-comment">/* aliases */</span>
  <span class="hljs-keyword">using</span> executor_memory_allocator_type = __executor_memory_allocator_type__;

  <span class="hljs-comment">/* member functions */</span>
  <span class="hljs-function">executor_memory_allocator_type <span class="hljs-title">executor_memory_allocator</span><span class="hljs-params">()</span> <span class="hljs-keyword">const</span></span>;

  ...
};

<span class="hljs-comment">/* managed_ptr class template */</span>
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;
<span class="hljs-keyword">class</span> managed_ptr {
<span class="hljs-keyword">public</span>:

  <span class="hljs-comment">/* aliases */</span>
  <span class="hljs-keyword">using</span> value_type              = __undefined_attributes__ T;
  <span class="hljs-keyword">using</span> pointer                 = value_type *;
  <span class="hljs-keyword">using</span> const_pointer           = <span class="hljs-keyword">const</span> value_type *;
  <span class="hljs-keyword">using</span> reference               = value_type &amp;;
  <span class="hljs-keyword">using</span> const_reference         = <span class="hljs-keyword">const</span> value_type &amp;;
  <span class="hljs-keyword">using</span> host_executor_type      = __host_executor_type__;
  <span class="hljs-keyword">using</span> executor_allocator_type = host_executor_type::executor_memory_allocator_type;

  <span class="hljs-comment">/* constructors */</span>
  managed_ptr(pointer); <span class="hljs-comment">// (1)</span>
  <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Allocator&gt;
  managed_ptr(Allocator allocator = executor_allocator_type{}); <span class="hljs-comment">// (2)</span>

  <span class="hljs-comment">/* special member functions */</span>
  managed_ptr(<span class="hljs-keyword">const</span> managed_ptr &amp;);
  managed_ptr(managed_ptr &amp;&amp;);
  managed_ptr &amp;<span class="hljs-keyword">operator</span>=(<span class="hljs-keyword">const</span> managed_ptr &amp;);
  managed_ptr &amp;<span class="hljs-keyword">operator</span>=(managed_ptr &amp;&amp;);
  ~managed_ptr();

  <span class="hljs-comment">/* member functions */</span>
  host_executor_type &amp;executor() <span class="hljs-keyword">const</span>;
  <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Executor&gt;
  <span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">is_allocated</span><span class="hljs-params">(Executor = host_executor_type{})</span> <span class="hljs-keyword">const</span></span>;
  <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Executor&gt;
  <span class="hljs-function"><span class="hljs-keyword">bool</span> <span class="hljs-title">is_accessible</span><span class="hljs-params">(Executor = host_executor_type{})</span> <span class="hljs-keyword">const</span></span>;

  <span class="hljs-comment">/* operators of const T instantiation */</span>
  const_reference <span class="hljs-keyword">operator</span>*() <span class="hljs-keyword">const</span>;
  const_pointer <span class="hljs-keyword">operator</span>-&gt;() <span class="hljs-keyword">const</span>;

  <span class="hljs-comment">/* operators of non-const T instantiation */</span>
  reference <span class="hljs-keyword">operator</span>*() <span class="hljs-keyword">const</span>;
  pointer <span class="hljs-keyword">operator</span>-&gt;() <span class="hljs-keyword">const</span>;
};

<span class="hljs-comment">/* extended retuirements for executor_future_t */</span>
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> T&gt;
<span class="hljs-keyword">class</span> executor_future_t {
  ...

  <span class="hljs-comment">/* synchronization member functions */</span>
  <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Executor, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
  future_type_t&lt;<span class="hljs-keyword">void</span>&gt; put(Executor, ManagedPtrN...);
  <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
  future_type_t&lt;<span class="hljs-keyword">void</span>&gt; get(ManagedPtrTN...);
  <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> SynchronizationChannel, <span class="hljs-keyword">typename</span> SrcExecutor,
            <span class="hljs-keyword">typename</span> DestExecutor, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
  future_type_t&lt;<span class="hljs-keyword">void</span>&gt;
  sync(SynchronizationChannel = __default_synchronization_channel__{},
       SrcExecutor, DestExecutor, ManagedPtrN...);

  <span class="hljs-comment">/* allocation member functions */</span>
  <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Executor, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
  future_type_t&lt;<span class="hljs-keyword">void</span>&gt; allocate(Executor, ManagedPtrN...);
  <span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Executor, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
  future_type_t&lt;<span class="hljs-keyword">void</span>&gt; deallocate(Executor, ManagedPtrN...);

  ...
};

<span class="hljs-comment">/* synchronization functions */</span>
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Executor, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
future_type_t&lt;<span class="hljs-keyword">void</span>&gt; put(Executor, ManagedPtrN...);
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Executor, <span class="hljs-keyword">typename</span> Predicate, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
future_type_t&lt;<span class="hljs-keyword">void</span>&gt; then_put(Executor, Predicate, ManagedPtrN...);
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
future_type_t&lt;<span class="hljs-keyword">void</span>&gt; get(ManagedPtrTN...);
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Predicate, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
future_type_t&lt;<span class="hljs-keyword">void</span>&gt; then_get(Predicate, ManagedPtrN...);
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> SynchronizationChannel, <span class="hljs-keyword">typename</span> SrcExecutor,
          <span class="hljs-keyword">typename</span> DestExecutor, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
future_type_t&lt;<span class="hljs-keyword">void</span>&gt;
sync(SynchronizationChannel = __default_synchronization_channel__{},
     SrcExecutor, DestExecutor, ManagedPtrN...);
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> SynchronizationChannel, <span class="hljs-keyword">typename</span> SrcExecutor,
          <span class="hljs-keyword">typename</span> DestExecutor, <span class="hljs-keyword">typename</span> Predicate, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
future_type_t&lt;<span class="hljs-keyword">void</span>&gt;
then_sync(SynchronizationChannel = __default_synchronization_channel__{},
          SrcExecutor, DestExecutor, Predicate, ManagedPtrN...);

<span class="hljs-comment">/* allocation functions */</span>
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Executor, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
future_type_t&lt;<span class="hljs-keyword">void</span>&gt; allocate(Executor, ManagedPtrN...);
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Executor, <span class="hljs-keyword">typename</span> Predicate, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
future_type_t&lt;<span class="hljs-keyword">void</span>&gt; then_allocate(Executor, Predicate, ManagedPtrN...);
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Executor, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
future_type_t&lt;<span class="hljs-keyword">void</span>&gt; deallocate(Executor, ManagedPtrN...);
<span class="hljs-keyword">template</span> &lt;<span class="hljs-keyword">typename</span> Executor, <span class="hljs-keyword">typename</span> Predicate, <span class="hljs-keyword">typename</span>... ManagedPtrN&gt;
future_type_t&lt;<span class="hljs-keyword">void</span>&gt; then_deallocate(Executor, Predicate,
                                              ManagedPtrN...);

<span class="hljs-comment">/* executor traits */</span>
<span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> T&gt; <span class="hljs-keyword">struct</span> can_put;
<span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> T&gt; <span class="hljs-keyword">struct</span> can_get;
<span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> T&gt; <span class="hljs-keyword">struct</span> can_sync;
<span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> T&gt; <span class="hljs-keyword">struct</span> can_allocate;
<span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> T&gt; <span class="hljs-keyword">struct</span> can_deallocate;
<span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> T&gt; <span class="hljs-keyword">constexpr</span> <span class="hljs-keyword">bool</span> can_put_v = can_put&lt;T&gt;::value;
<span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> T&gt; <span class="hljs-keyword">constexpr</span> <span class="hljs-keyword">bool</span> can_get_v = can_get&lt;T&gt;::value;
<span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> T&gt; <span class="hljs-keyword">constexpr</span> <span class="hljs-keyword">bool</span> can_sync_v = can_sync&lt;T&gt;::value;
<span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> T&gt; <span class="hljs-keyword">constexpr</span> <span class="hljs-keyword">bool</span> can_allocate_v = can_allocate&lt;T&gt;::value;
<span class="hljs-keyword">template</span>&lt;<span class="hljs-keyword">class</span> T&gt; <span class="hljs-keyword">constexpr</span> <span class="hljs-keyword">bool</span> can_deallocate_v = can_deallocate&lt;T&gt;::value;

}  <span class="hljs-comment">// namespace execution</span>
}  <span class="hljs-comment">// namespace concurrency_v2</span>
}  <span class="hljs-comment">// namespace experimental</span>
}  <span class="hljs-comment">// namespace std</span>
</code></pre><p><em>Figure 1: Execution synopsis</em></p><h3 id="3.2.-requirements-on-executor-and-execution-contex"><a name="3.2.-requirements-on-executor-and-execution-contex" href="p0567r1.html#3.2.-requirements-on-executor-and-execution-contex"></a>3.2. Requirements on Executor and Execution Contex</h3><p>In order to facilitate the <code>managed_ptr</code>, it is necessary to introduce requirements on the <em>executor</em> and the <em>execution context</em>; the class associated with an <em>executor</em> which encapsulates the underlying execution resource on which <em>execution agents</em> are executed.</p><h4 id="3.2.1.-execution-context-memory-region"><a name="3.2.1.-execution-context-memory-region" href="p0567r1.html#3.2.1.-execution-context-memory-region"></a>3.2.1. Execution Context Memory Region</h4><p>In addition to a number of <em>execution agents</em>, an <em>execution context</em> must also encapsulate at least one memory region that is concurrently accessible by all <em>execution agents</em> of any single invocation of an execution function. It is not required for the memory region to be concurrently accessible to <em>execution agents</em> of another invocation of an execution function or <em>execution agents</em> executing on a different <em>execution context</em>.</p><blockquote>
<p>This requirement currently satisfies the coarse-grained level of synchronisation described in requirement 2. These requirements will be loosened in a later iteration of this paper when a suitable interface for fine-grained synchronisation is included. The current proposal for this is described in section 4.1 as future work.</p>
</blockquote><h4 id="3.2.2.-executor-memory-allocator"><a name="3.2.2.-executor-memory-allocator" href="p0567r1.html#3.2.2.-executor-memory-allocator"></a>3.2.2. Executor Memory Allocator</h4><p>The <em>execution context</em> must also provide an alias to an allocator type called <code>executor_memory_allocator_type</code> that is capable of allocating memory in it’s memory region, and a member function for retrieving an instance of this type called <code>executor_memory_allocator()</code>.</p><h3 id="3.3.-managed-pointer-class-template"><a name="3.3.-managed-pointer-class-template" href="p0567r1.html#3.3.-managed-pointer-class-template"></a>3.3. Managed Pointer Class Template</h3><p>The proposed addition to the standard library is the <code>managed_ptr</code> class template. The <code>managed_ptr</code> is a smart pointer which has ownership of a virtual allocation of contiguous memory that can be shared between any number of devices via a set of synchronisation operations.</p><p>The <code>managed_ptr</code> class template has a single template parameter; <code>T</code> specifying the type of the pointer.</p><p>The type parameter <code>T</code> specifies the pointer type, any <code>T</code> satisfies the <code>managed_ptr</code> pointer type requirements if:</p><blockquote>
<p>Another solution for read-only access was considered where access to a <code>managed_ptr</code> instance could be dynamically specified via properties using the proposed <code>array_ref</code> interface [10]. However, it was felt that this approach would be too verbose and would introduce unnecessary overhead for cases which did not require the properties to be specified. Additionally, as many implementations would wish to make use of read-only partitions of memory this could require an implementation to copy in an out of this memory partition dynamically which could introduce opaque latency in synchronisation.</p>
</blockquote><ul>
<li><code>T</code> is a standard layout type.</li><li><code>T</code> is trivially copy-constructible.</li></ul><p>If <code>T</code> is a const type then the <code>managed_ptr</code> is considered to be read-only. This allows implementations to optimise the allocation of memory in read-only segments of the memory region. Additionally, the de-reference and pointer operators return a const pointer and reference respectively preventing writing to the memory.</p><h4 id="3.3.1.-construction-and-destuction"><a name="3.3.1.-construction-and-destuction" href="p0567r1.html#3.3.1.-construction-and-destuction"></a>3.3.1. Construction and destuction</h4><p>A <code>managed_ptr</code> can be constructed in two ways:</p><ul>
<li>for constructor (1) the  <code>managed_ptr</code> takes an existing pointer and does not allocate memory.</li><li>for constructor (2) the  <code>managed_ptr</code> allocates using the allocator specified by the allocatorT parameter, which defaults to the allocator of the associated <em>executor</em> if one is not provided.</li></ul><p>The default constructor for <code>T</code> must not be called by the <code>managed_ptr</code> during construction of the <code>managed_ptr</code>.</p><p>The destructor must not perform any synchronisation operations.</p><h4 id="3.3.2.-execution-context-capabilities"><a name="3.3.2.-execution-context-capabilities" href="p0567r1.html#3.3.2.-execution-context-capabilities"></a>3.3.2. Execution context capabilities</h4><p>In order to support a wide range of systems, both heterogeneous and distributed, a high-level abstraction for the <code>managed_ptr</code> is necessary, however not all devices will be able to support of all of a <code>managed_ptr</code>s capabilities.</p><p>As the <code>managed_ptr</code> can be used on different devices it can have different capabilities depending on where it is currently being used. The <code>managed_ptr</code> will likely be compiled separately or at least have different restrictions imposed on the code that is executed depending on where it is used. It is important to be able to determine what capabilities the <code>managed_ptr</code> supports where it is being used.</p><p>These capabilities can be queried via a series of compile-time traits. These are <code>can_put_v</code>, <code>can_get_v</code>, <code>can_sync_v</code>, <code>can_allocate_v</code> and <code>can_deallocate_v</code>. Each of these compile time traits can be used to query whether a particular executor class supports the synchronisation or allocation function of the same name.</p><blockquote>
<p>These traits are currently limited to the synchronisation and allocation functions however this can be extended to include queries for other capabilities.</p>
</blockquote><h4 id="3.3.3.-memory-accessibiity"><a name="3.3.3.-memory-accessibiity" href="p0567r1.html#3.3.3.-memory-accessibiity"></a>3.3.3. Memory accessibiity</h4><p>During the lifetime of a <code>managed_ptr</code> it’s managed memory allocation can exist in the memory region(s) associated with any number of <em>execution contexts</em>, but may only be accessible in one of these memory regions at any given time. The <em>execution context</em> who’s memory region is currently accessible is said to be the accessible <em>execution context</em>.</p><blockquote>
<p>This limited may be relaxed in a future version of the paper when a <code>managed_ptr</code> can be concurrently accessed in more than one memory region. In this case, there could be more than one accessible memory region. This is further described in section 4.1.</p>
</blockquote><p>The <code>managed_ptr</code> must maintain a reference to the current accessible <em>execution context</em>.</p><p>The associated <em>execution context</em> and <em>executor</em> of a <code>managed_ptr</code> can also be accessible, the <code>managed_ptr</code> has a member function for querying wether the associated <em>execution context</em> and <em>executor</em> is accessible; <code>is_accessible()</code>.</p><p>The data at the memory region of the <code>managed_ptr</code>s associated <em>execution context</em> and <em>executor</em> can be read and modified (if the type <code>T</code> is a non-const type) via the de-reference and pointer operators.</p><h4 id="3.3.4.-resource-aquisition"><a name="3.3.4.-resource-aquisition" href="p0567r1.html#3.3.4.-resource-aquisition"></a>3.3.4. Resource aquisition</h4><p>The <code>managed_ptr</code> must allocate memory within the memory region of any execution context which that <code>managed_ptr</code> is accessible on via that execution context’s allocator. This does not have to be in tandem or on construction of the <code>managed_ptr</code> instance, the point at which allocation happens for each execution context is implementation defined, the only requirement is that the memory must be allocated (if not already so) prior to the <code>managed_ptr</code> being accessed on said execution context. Additionally, the <code>managed_ptr</code> must deallocate in all memory regions that the <code>managed_ptr</code> instance has been allocated on, during its destructor.</p><p>If a user wishes to explicitly allocate or deallocate memory for a <code>managed_ptr</code> instance on a particular execution context, this can be done by calling the allocation operations <code>allocate</code>, <code>then_allocate</code>, <code>deallocate</code> and <code>then_deallocate</code>. Each of which is an asynchronous operation which performs an allocation or allocation in a particular execution context and returns a future to the completion of the operation.</p><p>If any memory allocation or deallocation operations fails, then an exception is thrown and stored in the future object that is returned by the operations which triggered the allocation operation.</p><h4 id="3.3.5.-synchronization"><a name="3.3.5.-synchronization" href="p0567r1.html#3.3.5.-synchronization"></a>3.3.5. Synchronization</h4><p>For an <strong>execution context</strong> to be the accessible <strong>execution context</strong>, if it is not already, a synchronisation operation is required. A synchronisation operation is an implementation defined asynchronous set of commands which moves the data from the currently accessible memory region to another memory region which returns a future object that can be used to wait for the operation to complete. From the point at which a synchronisation operation is triggered the currently accessible memory region is no longer accessible. Once the synchronisation point is complete (i.e. the future returned from the synchronisation operation is complete) the memory region the data is being synchronised to is now the accessible memory region.</p><p>Synchronisation operations are coarse-grained synchronisation in that they synchronise the entire managed memory allocation of a <code>managed_ptr</code>.</p><blockquote>
<p>This limitation may be relaxed in a future version of the paper when a <code>managed_ptr</code> can be concurrently accessed in more than one memory region. In this case, there synchronisation could be performed at smaller granularities using mapping operations or atomic operations. This is further described in section 4.1.</p>
</blockquote><p>There are three synchronisation operations; <code>get</code>, <code>put</code> and <code>sync</code>, each taking one or more <code>managed_ptr</code> parameters. These synchronisation operations perform the following synchronisation for each <code>managed_ptr</code> parameter:</p><ul>
<li>The <code>get</code> operation synchronises the data at the memory region at a particular <em>executor</em> to the memory region at the <em>executor</em> associated with the <code>managed_ptr</code>.</li><li>The <code>put</code> operation synchronises the data at the memory region at the <em>executor</em> associated with the <code>managed_ptr</code> to the memory region at a particular <em>executor</em>.</li><li>The <code>sync</code> operation synchronises the data at the memory region at one particular <em>executor</em> to the memory region at another particular <em>executor</em>.</li></ul><blockquote>
<p>In the previous revision of this paper R0, it was also possible to implicitly trigger synchronisation operations by simply passing a <code>managed_ptr</code> to a control structure such as <code>async</code>. However, this has been removed due to a limitation that may affect implementations. This is described in section 4.2.</p>
</blockquote><p>There are a further three synchronisation operations; <code>then_get</code>, <code>then_put</code> and <code>then_sync</code>, which are equivalent to <code>get</code>, <code>put</code> and <code>sync</code> but take a predicate future parameter that the operation must wait on before executing. These are used to provide a continuations interface for synchronisation operations. Equivalent operations to these are also required as member functions on the future type. This is described further in section 3.4.</p><p>If any synchronisation operations fail, then an exception is thrown and stored in the future object that is returned by the operations which triggered the synchronisation operation.</p><p>Below is an example of using the <code>put</code> and <code>get</code> synchronisation operations to synchronise data to and from a GPU:</p><pre class="cpp hljs"><code class="cpp" data-origin="<pre><code class=&quot;cpp&quot;>using std::experimental;

/* Define the data structure to share across devices. */
struct my_data { /* ... */ };

/* Construct a context and executor for executing work on the GPU */
gpu_execution_context gpuContext;
auto gpuExecutor = gpuContext.executor();

/* Retrieve gpu allocator */
auto gpuAllocator = gpuContext.allocator();

/* Construct a managed_ptr ptraA allocated on the memory region of the host executor */
execution::managed_ptr&amp;lt;my_data&amp;gt; ptrA;

/* Construct a managed_ptr ptrB allocated on the memory region of the GPU executor */
execution::managed_ptr&amp;lt;my_data&amp;gt; ptrB(gpuAllocator);

/* Populate ptrA */
populate(ptrA);

/* Construct a series of compute and data operations */
auto fut =
  execution::put(gpuExecutor, ptrA)
    .then_async_execute(gpuExecutor, [=]() { /* ... */ })
      .then_get(ptrB);

/* Wait on the operations to execute */
fut.wait();

/* Print the result */
print(ptrB);
</code></pre>"><span class="hljs-keyword">using</span> <span class="hljs-built_in">std</span>::experimental;

<span class="hljs-comment">/* Define the data structure to share across devices. */</span>
<span class="hljs-keyword">struct</span> my_data { <span class="hljs-comment">/* ... */</span> };

<span class="hljs-comment">/* Construct a context and executor for executing work on the GPU */</span>
gpu_execution_context gpuContext;
<span class="hljs-keyword">auto</span> gpuExecutor = gpuContext.executor();

<span class="hljs-comment">/* Retrieve gpu allocator */</span>
<span class="hljs-keyword">auto</span> gpuAllocator = gpuContext.allocator();

<span class="hljs-comment">/* Construct a managed_ptr ptraA allocated on the memory region of the host executor */</span>
execution::managed_ptr&lt;my_data&gt; ptrA;

<span class="hljs-comment">/* Construct a managed_ptr ptrB allocated on the memory region of the GPU executor */</span>
execution::managed_ptr&lt;my_data&gt; ptrB(gpuAllocator);

<span class="hljs-comment">/* Populate ptrA */</span>
populate(ptrA);

<span class="hljs-comment">/* Construct a series of compute and data operations */</span>
<span class="hljs-keyword">auto</span> fut =
  execution::put(gpuExecutor, ptrA)
    .then_async_execute(gpuExecutor, [=]() { <span class="hljs-comment">/* ... */</span> })
      .then_get(ptrB);

<span class="hljs-comment">/* Wait on the operations to execute */</span>
fut.wait();

<span class="hljs-comment">/* Print the result */</span>
print(ptrB);
</code></pre><p><em>Figure 2: Example of synchronization operations</em></p><h3 id="3.4.-requirements-on-the-future-type"><a name="3.4.-requirements-on-the-future-type" href="p0567r1.html#3.4.-requirements-on-the-future-type"></a>3.4. Requirements on the Future Type</h3><p>The executor future type <code>executor_future_t</code> that is either the result of or calls a synchronisation continuation must provide the member functions <code>put</code>, <code>get</code>, <code>sync</code>, <code>allocate</code> and <code>deallocate</code> as described in the execution synopsis (Figure 1).</p><h3 id="3.5.-optimising-synchronisation-operations-using-synchronisation-channels"><a name="3.5.-optimising-synchronisation-operations-using-synchronisation-channels" href="p0567r1.html#3.5.-optimising-synchronisation-operations-using-synchronisation-channels"></a>3.5. Optimising Synchronisation Operations using Synchronisation Channels</h3><p>Synchronisation channels are objects which represent a connection between two execution contexts, for example between two remote devices or between an I/O device and a remote device. The default synchronisation channel which supports synchronisation between all execution contexts is that which synchronises via the host executor. However, implementers can provide their own synchronisation channels which can be used by the user in synchronisation operations to optimise them.</p><p>For example:</p><pre class="cpp hljs"><code class="cpp" data-origin="<pre><code class=&quot;cpp&quot;>using namespace std::experimental::concurrency_v2::execution;

struct my_data { /* ... */ };

vendor_x::input_stream_execution_context inputStreamContext;
vendor_x::gpu_execution_context gpuContext;
vendor_x::input_stream_to_gpu_channel inputStreamToGPUChannel;

auto inputStreamExec = inputStreamContext.executor();

auto gpuExec = gpuContext.executor();

managed_ptr&amp;lt;my_data&amp;gt; ptr(inputStreamContext.executor_memory_allocator());

for (;;) {
  auto fut =
    execute(inputStreamExec, [=](){ read_input(ptr); })
      .then_sync(inputStreamToGPUChannel, inputStreamExec, gpuExec)
        .then_execute(gpuExec, [=](){ process(ptr); })
  post_process(fut.get());
}
</code></pre>"><span class="hljs-keyword">using</span> <span class="hljs-keyword">namespace</span> <span class="hljs-built_in">std</span>::experimental::concurrency_v2::execution;

<span class="hljs-keyword">struct</span> my_data { <span class="hljs-comment">/* ... */</span> };

vendor_x::input_stream_execution_context inputStreamContext;
vendor_x::gpu_execution_context gpuContext;
vendor_x::input_stream_to_gpu_channel inputStreamToGPUChannel;

<span class="hljs-keyword">auto</span> inputStreamExec = inputStreamContext.executor();

<span class="hljs-keyword">auto</span> gpuExec = gpuContext.executor();

managed_ptr&lt;my_data&gt; ptr(inputStreamContext.executor_memory_allocator());

<span class="hljs-keyword">for</span> (;;) {
  <span class="hljs-keyword">auto</span> fut =
    execute(inputStreamExec, [=](){ read_input(ptr); })
      .then_sync(inputStreamToGPUChannel, inputStreamExec, gpuExec)
        .then_execute(gpuExec, [=](){ process(ptr); })
  post_process(fut.get());
}
</code></pre><p><em>Figure 3: Synchronization Channels Example</em></p><blockquote>
<p>This is not the most efficient example, it could be improved by double buffering the synchronisation and computation, though it demonstrates how channels can be used to avoid synchronising via a host executor.</p>
</blockquote><h2 id="4.-future-work"><a name="4.-future-work" href="p0567r1.html#4.-future-work"></a>4. Future Work</h2><p>There are many other considerations to make when looking at a model for data movement for heterogeneous and distributed systems, however, this paper aims to establish a foundation which can be extended to include other paradigms in the future.</p><h3 id="4.1.-shared-accessibility"><a name="4.1.-shared-accessibility" href="p0567r1.html#4.1.-shared-accessibility"></a>4.1. Shared Accessibility</h3><p>Systems which support a unified address space (i.e. sharing a single memory region across different <em>execution contexts</em>) could allow for a <code>managed_ptr</code> instance to share accessibility between multiple <em>execution contexts</em>. This would allow a <code>managed_ptr</code> to be concurrently accessible by multiple <em>execution contexts</em> via the use of atomics providing those <em>execution contexts</em> share a memory region.</p><p>The current proposed solution is that the <code>managed_ptr</code> have an additional template parameter specifying the <code>memory_mode</code>, allowing it to be specialised for supporting different memory architectures. The <code>memory_mode</code> of a <code>managed_ptr</code> can be either <code>memory_mode::discrete</code>, <code>memory_mode::unified</code> or <code>memory_model::shared</code>:</p><ul>
<li>The memory mode <code>memory_mode::discrete</code> can only have a single accessible execution context so cannot be accessed concurrently and has discrete memory regions so cannot support passing pointer-based structures.</li><li>The memory mode <code>memory_mode::unified</code> can only have a single accessible execution context so cannot be accessed concurrently but has a unified memory region so can support passing pointer-based structures.</li><li>The memory mode <code>memory_mode::shared</code> can have multiple accessible execution contexts so can be accessed concurrently via the use of atomics and has a unified memory region so can support passing pointer-based structures.</li></ul><p>This idea is not yet been integrated into to the rest of the proposal and is considered future work as the design has not yet been fully fleshed out. There are other factors that have to be considered such as the execution context - memory region topology and atomic operations.</p><h3 id="4.2.-implicit-synchronization"><a name="4.2.-implicit-synchronization" href="p0567r1.html#4.2.-implicit-synchronization"></a>4.2. Implicit Synchronization</h3><p>In a previous revision of this paper R0, it was possible to trigger implicit synchronisation operations by simply passing a <code>managed_ptr</code> to a control structure such as <code>async</code>. However, this has been removed due to limitations that may affect an implementation. As the current executor interface does not support variadic execution function parameters, an implementation would be required to trigger synchronisation operations on all control structures for <code>managed_ptr</code> captures. Firstly this may incur unwanted overhead and secondly, this could potentially require static reflection for an optimal implementation. For these reasons this feature has been removed and instead kept as a potential future work that could be incorporated if proven to be implementable without creating overhead.</p><h3 id="4.3.-additional-containers"><a name="4.3.-additional-containers" href="p0567r1.html#4.3.-additional-containers"></a>4.3. Additional Containers</h3><p>We may wish to extend this principle of a managed pointer to other containers that would be useful to share across heterogeneous and distributed systems such as vectors or arrays. This could be done by having containers such as <code>managed_vector</code> or <code>managed_array</code> that would have similar requirements to the standard containers of the same names in terms of storage and access yet would be extended to support access from remote devices as with the <code>managed_ptr</code>.</p><h3 id="4.4.-hierarchical-memory-architectures"><a name="4.4.-hierarchical-memory-architectures" href="p0567r1.html#4.4.-hierarchical-memory-architectures"></a>4.4. Hierarchical Memory Architectures</h3><p>While CPUs have a single flat memory region with a single address space, most heterogeneous devices have a more complex hierarchy of memory regions each with their own distinct address spaces. Each of these memory regions has a unique access scope, semantics and latency. Some heterogeneous programming models provide a unified or shared memory address space to allow more generic programming such as OpenCL 2.x [6], HSA [7] and CUDA [8], however, this will not always result in the most efficient memory access. This can be supported either in hardware where the host CPU and remote devices share the same physical memory or software where a cross-device cache coherency system is in place, and there are various different levels at which this feature can be supported. In general, this means that pointers that are allocated in the host CPU memory region can be used directly in the memory regions of remote devices, though this sometimes requires mapping operations to be performed.</p><p>We may wish to investigate this feature further to incorporate support for this kind of systems, ensuring that the <code>managed_ptr</code> can fully utilise the memory regions on these systems.</p><h2 id="appendix-a:-naming-considerations"><a name="appendix-a:-naming-considerations" href="p0567r1.html#appendix-a:-naming-considerations"></a>Appendix A: Naming considerations</h2><p>During the development of this paper, many names were considered both for the <code>managed_ptr</code> itself and for its interface.</p><p>Alternative names that were considered for <code>managed_ptr</code> were <code>temporal</code> as it described a container which gave temporal access to a managed memory allocation, <code>managed_container</code> as the original design was based on the <code>std::vector</code> container and <code>managed_array</code> as the managed memory allocation is statically sized.</p><p>Alternative names for the <code>put()</code> and <code>get()</code> interface were <code>acquire()</code> and <code>release()</code> as you were effectively acquiring and releasing the managed memory allocation and <code>send()</code> and <code>receive()</code> as you are effectively sending and receiving back the managed memory allocation.</p><h2 id="references"><a name="references" href="p0567r1.html#references"></a>References</h2><p>[1] P0443R1 A Unified Executors Proposal for C++:<br><a href="p0443r1.html">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/p0443r1.html</a></p><p>[2] SYCL 1.2 Specification:<br><a href="https://www.khronos.org/registry/sycl/specs/sycl-1.2.pdf">https://www.khronos.org/registry/sycl/specs/sycl-1.2.pdf</a></p><p>[3] STEllAR-GROUP HPX Project:<br><a href="https://github.com/STEllAR-GROUP/hpx">https://github.com/STEllAR-GROUP/hpx</a></p><p>[4] KoKKos Project:<br><a href="https://github.com/kokkos">https://github.com/kokkos</a></p><p>[5] Raja Project:<br><a href="http://software.llnl.gov/RAJA/">http://software.llnl.gov/RAJA/</a></p><p>[6] OpenCL 2.2 Specification<br><a href="https://www.khronos.org/registry/OpenCL/specs/opencl-2.2.pdf">https://www.khronos.org/registry/OpenCL/specs/opencl-2.2.pdf</a></p><p>[7] HSA Specification<br><a href="http://www.hsafoundation.com/standards/">http://www.hsafoundation.com/standards/</a></p><p>[8] CUDA Unified Memory<br><a href="https://devblogs.nvidia.com/parallelforall/unified-memory-in-cuda-6/">https://devblogs.nvidia.com/parallelforall/unified-memory-in-cuda-6/</a></p><p>[9] HAM-Offload Programming Model for Distributed Systems<br><a href="https://github.com/noma/ham">https://github.com/noma/ham</a></p><p>[10] Polymorphic Multidimensional Array Reference<br><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0009r3.html">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2016/p0009r3.html</a></p><p>[11] MYO Programming Model (Mine Yours Ours)<br><a href="http://pleiades.ucsc.edu/doc/intel/mic/myo/tutorials/README.txt">http://pleiades.ucsc.edu/doc/intel/mic/myo/tutorials/README.txt</a></p><p>[12] Programming for Multicore and Many-core Products including Intel® Xeon® processors and Intel® Xeon Phi™ X100 Product Family coprocessors<br><a href="https://software.intel.com/en-us/articles/programming-for-multicore-and-many-core-products">https://software.intel.com/en-us/articles/programming-for-multicore-and-many-core-products</a></p><p>[13] P0687r0 Data Movement in C++<br><a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/P0687r0.html">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/P0687r0.html</a></p>

<footer style="position:fixed; font-size:.8em; text-align:right; bottom:0px; margin-left:-25px; height:20px; width:100%;">generated by <a href="http://pad.haroopress.com" target="_blank">haroopad</a></footer>
</body>
</html>
